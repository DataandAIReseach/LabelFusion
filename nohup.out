2025-11-06 11:41:45,836 - INFO - Initializing OpenAIClassifier
2025-11-06 11:41:45,837 - INFO - Text column: text
2025-11-06 11:41:45,837 - INFO - Label columns: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']
2025-11-06 11:41:45,837 - INFO - Multi-label: True
2025-11-06 11:41:45,837 - INFO - Few-shot mode: few_shot
2025-11-06 11:41:46,041 - INFO - PromptEngineer initialized with model: gpt-5-nano
2025-11-06 11:41:46,041 - INFO - LLM generator initialized with provider: openai
2025-11-06 11:41:46,041 - INFO - Using API key for: openai
2025-11-06 11:41:46,064 - INFO - üìÅ Results will be saved to: outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-46_goemotions_0.1pct_2025-11-06_11-41-28_openai
2025-11-06 11:41:46,064 - INFO - üî¨ Experiment ID: 2025-11-06_11-41-46_goemotions_0.1pct_2025-11-06_11-41-28_openai
2025-11-06 11:41:46,064 - INFO - Configuration setup - Batch size: 32, Threshold: 0.5
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-11-06 11:42:06,379 - INFO - Saved predictions to JSON: outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/predictions/validation_predictions_6af59bb951cc.json
2025-11-06 11:42:06,404 - INFO - Saved predictions to CSV: outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/predictions/validation_predictions_6af59bb951cc.csv
2025-11-06 11:42:06,412 - INFO - Saved metrics to: outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/metrics/roberta_classifier_validation_metrics.yaml
2025-11-06 11:42:06,414 - INFO - Saved model config to: outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/roberta_classifier_config.yaml
2025-11-06 11:42:06,421 - INFO - Saved experiment summary to: outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/experiment_summary.yaml
2025-11-06 11:42:09,266 - INFO - Saved predictions to JSON: outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/predictions/test_predictions_6aa2ecb5ea16.json
2025-11-06 11:42:09,291 - INFO - Saved predictions to CSV: outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/predictions/test_predictions_6aa2ecb5ea16.csv
2025-11-06 11:42:09,299 - INFO - Saved metrics to: outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/metrics/roberta_classifier_test_metrics.yaml
2025-11-06 11:42:09,301 - INFO - ================================================================================
2025-11-06 11:42:09,301 - INFO - STARTING PREDICTION PROCESS
2025-11-06 11:42:09,301 - INFO - ================================================================================
2025-11-06 11:42:09,301 - INFO - Test data shape: (500, 37)
2025-11-06 11:42:09,301 - INFO - Training data shape: (207389, 37)
2025-11-06 11:42:09,301 - INFO - 
STEP 1: Data Preparation and Validation
2025-11-06 11:42:09,353 - INFO - Combined dataset shape: (207889, 37)
2025-11-06 11:42:09,353 - INFO - Starting simple DataFrame validation...
2025-11-06 11:42:09,353 - INFO - Validating training data: (207389, 37)
2025-11-06 11:42:09,353 - INFO - Performing basic data validation...
2025-11-06 11:42:09,384 - INFO - Basic validation passed - Text column: text, Label columns: 28
2025-11-06 11:42:09,385 - INFO - Validating test data: (500, 37)
2025-11-06 11:42:09,385 - INFO - Performing basic data validation...
2025-11-06 11:42:09,388 - INFO - Basic validation passed - Text column: text, Label columns: 28
2025-11-06 11:42:09,388 - INFO - DataFrame validation completed successfully
2025-11-06 11:42:09,388 - INFO - Training data: (207389, 37)
2025-11-06 11:42:09,388 - INFO - Test data: (500, 37)
2025-11-06 11:42:09,388 - INFO - Data preparation and validation completed successfully
2025-11-06 11:42:09,388 - INFO - 
STEP 2: Prompt Configuration Setup
2025-11-06 11:42:09,388 - INFO - Prompt configuration completed
2025-11-06 11:42:09,388 - INFO - 
STEP 3: Engineering Prompts
2025-11-06 11:42:09,388 - INFO - Starting prompt engineering process...
2025-11-06 11:42:09,389 - INFO - Engineering prompts for 500 test samples
2025-11-06 11:42:09,389 - INFO - Using 207389 training samples for few-shot learning
2025-11-06 11:43:25,636 - INFO - Successfully engineered 500 prompts
2025-11-06 11:43:25,654 - INFO - All prompts rendered and added to DataFrame
2025-11-06 11:43:25,654 - INFO - Prompts engineered for 500 samples
2025-11-06 11:43:25,654 - INFO - 
STEP 4: Generating Predictions
2025-11-06 11:43:25,654 - INFO - Processing 500 samples in 16 batches of size 32
================================================================================
DATA AVAILABILITY EXPERIMENT - FUSION ENSEMBLE ON GOEMOTIONS
================================================================================

Configuration:
  Data directory: data/goemotions
  Training percentages: ['0.1%', '0.2%', '0.3%', '0.4%', '0.5%', '0.6%', '0.7%', '0.8%', '0.9%', '1%', '10%', '20%', '30%', '40%', '50%', '60%', '70%', '80%', '90%', '100%']
  LLM provider: openai
  Output directory: outputs/goemotions_availability_experiments
  Auto-use cache: True
  Cache directory: cache
  Evaluate baselines: True
Loading datasets from data/goemotions...
  Training samples: 207389
  Validation samples: 500
  Test samples: 500

Dataset configuration:
  Text column: text
  Label columns: 28 emotions

================================================================================
EXPERIMENT: Training with 0.1pct of training data
================================================================================

Creating stratified subset with 0% of training data...
  Warning: Stratification failed for 0.1%, using random sampling instead
  Subset size: 207 samples

Class distribution in subset:
admiration        15
amusement         11
anger             12
annoyance         12
approval          23
caring             8
confusion          8
curiosity          4
desire             1
disappointment     8
disapproval        9
disgust            9
embarrassment      0
excitement        11
fear               8
gratitude         18
grief              1
joy                6
love               7
nervousness        2
optimism           7
pride              0
realization        7
relief             4
remorse            2
sadness            5
surprise           5
neutral           51
dtype: int64

Checking for existing LLM caches...
  Using current DataFrame hashes:
    Val Hash:  7d1c2ba60bee
    Test Hash: e6a79327fd5c

Creating models...
Creating fusion ensemble...

--------------------------------------------------------------------------------
BASELINE 1: Evaluating RoBERTa (ML) model alone...
--------------------------------------------------------------------------------
Training RoBERTa on 207 samples...
Epoch 1/2
Train loader batches: 26 | batch_size: 8 | device: cuda
  [epoch 1] processing batch 0
  [epoch 1] processing batch 10
  [epoch 1] processing batch 20
  Average training loss: 0.5393
  Average validation loss: 0.3582
Epoch 2/2
Train loader batches: 26 | batch_size: 8 | device: cuda
  [epoch 2] processing batch 0
  [epoch 2] processing batch 10
  [epoch 2] processing batch 20
  Average training loss: 0.3425
  Average validation loss: 0.3040
‚úÖ Model training completed!
üìù Generating validation predictions...
üìÅ Prediction results saved: {'json': 'outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/predictions/validation_predictions_6af59bb951cc.json', 'csv': 'outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/predictions/validation_predictions_6af59bb951cc.csv', 'metrics': 'outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/metrics/roberta_classifier_validation_metrics.yaml'}
‚úÖ Validation predictions saved with accuracy: 0.0000
üìÅ Training results saved to: outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta
Evaluating RoBERTa on test set...
üìÅ Prediction results saved: {'json': 'outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/predictions/test_predictions_6aa2ecb5ea16.json', 'csv': 'outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/predictions/test_predictions_6aa2ecb5ea16.csv', 'metrics': 'outputs/goemotions_availability_experiments/train_0.1pct/experiments/2025-11-06_11-41-45_goemotions_0.1pct_2025-11-06_11-41-28_roberta/metrics/roberta_classifier_test_metrics.yaml'}

RoBERTa Test Results:
  Accuracy: 0.0000
  F1 Score (Weighted): 0.0000
  Precision (Weighted): 0.0000
  Recall (Weighted): 0.0000

--------------------------------------------------------------------------------
BASELINE 2: Evaluating OPENAI (LLM) model alone...
--------------------------------------------------------------------------------
Evaluating OPENAI on test set with FULL training data (with caching enabled)...

üîç Auto-cache enabled, checking for cached predictions...
‚ÑπÔ∏è  No cached prediction files found in cache/experimente/fusion_openai_cache_0.1pct
‚ÑπÔ∏è  No cached predictions found, running inference...
Validating input data...
Data preparation and validation passed
Setting up prompt configuration...
Prompt configuration ready
Engineering prompts for classification...
Starting prompt engineering...
500 prompts engineered
Rendering prompts...
Prompt engineering completed
500 prompts ready for processing
Generating predictions using LLM...
Processing in 16 batches...
Processing batches:   0%|          | 0/16 [00:00<?, ?it/s]Processing batches:   6%|‚ñã         | 1/16 [08:35<2:08:52, 515.48s/it]Processing batches:  12%|‚ñà‚ñé        | 2/16 [16:40<1:56:08, 497.73s/it]Processing batches:  19%|‚ñà‚ñâ        | 3/16 [25:26<1:50:36, 510.54s/it]2025-11-06 12:18:02,534 - WARNING - Binary response length (29) doesn't match classes count (28)
2025-11-06 12:18:02,534 - INFO - Truncated binary response to 28 labels
2025-11-06 12:18:02,534 - WARNING - Binary response length (29) doesn't match classes count (28)
2025-11-06 12:18:02,535 - INFO - Truncated binary response to 28 labels
Processing batches:  25%|‚ñà‚ñà‚ñå       | 4/16 [34:36<1:45:14, 526.24s/it]Processing batches:  31%|‚ñà‚ñà‚ñà‚ñè      | 5/16 [43:24<1:36:35, 526.89s/it]Processing batches:  38%|‚ñà‚ñà‚ñà‚ñä      | 6/16 [52:20<1:28:19, 529.98s/it]
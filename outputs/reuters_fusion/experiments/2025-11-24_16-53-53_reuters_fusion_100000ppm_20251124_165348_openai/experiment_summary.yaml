created_at: '2025-11-24T16:55:18.353424'
experiment_metadata:
  config: {}
  dataset_hash: ''
  environment:
    hostname: agq006
    platform: Linux-4.18.0-553.81.1.el8_10.x86_64-x86_64-with-glibc2.28
    python_version: 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13)
      [GCC 12.3.0]
    working_directory: /scratch-scc/users/u19147/LabelFusion
  experiment_id: 2025-11-24_16-53-53_reuters_fusion_100000ppm_20251124_165348_openai
  git_commit: e5f858798f447b100973adce6b0310abdae51260
  model_name: ''
  model_type: ''
  timestamp: '2025-11-24T16:53:53.695181'
file_structure:
  logs:
  - logs/experiment.log
  metrics:
  - metrics/openai_classifier_test_metrics.yaml
  models: []
  plots: []
  predictions:
  - predictions/test_predictions_aa685a6f1bc6.csv
  - predictions/test_predictions_aa685a6f1bc6.json
test_results: null
training_results:
  batch_size: 32
  classes:
  - earn
  - acq
  - money-fx
  - grain
  - crude
  - trade
  - interest
  - ship
  - wheat
  - corn
  classification_type: multi_label
  completed: true
  max_completion_tokens: 150
  metrics:
    f1: 0.8699124162802679
    hamming_loss: 0.030293663060278208
    micro_f1: 0.9697063369397217
    micro_precision: 0.9697063369397217
    micro_recall: 0.9697063369397217
    precision: 0.9003091190108191
    recall: 0.8560020607934056
    subset_accuracy: 0.8129829984544049
  model_name: gpt-5-nano
  model_type: llm
  num_labels: 10
  provider: openai
  temperature: 0.1
  test_samples: 647
  train_samples: 5842

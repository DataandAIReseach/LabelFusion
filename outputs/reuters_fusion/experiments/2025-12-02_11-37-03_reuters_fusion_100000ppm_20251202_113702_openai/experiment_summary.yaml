created_at: '2025-12-02T11:38:01.507932'
experiment_metadata:
  config: {}
  dataset_hash: ''
  environment:
    hostname: agq002
    platform: Linux-4.18.0-553.81.1.el8_10.x86_64-x86_64-with-glibc2.28
    python_version: 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13)
      [GCC 12.3.0]
    working_directory: /scratch-scc/users/u19147/LabelFusion
  experiment_id: 2025-12-02_11-37-03_reuters_fusion_100000ppm_20251202_113702_openai
  git_commit: bb47ce1039bb36f72a2110dff691998fd9b62cf2
  model_name: ''
  model_type: ''
  timestamp: '2025-12-02T11:37:03.114312'
file_structure:
  logs:
  - logs/experiment.log
  metrics:
  - metrics/openai_classifier_test_metrics.yaml
  models: []
  plots: []
  predictions:
  - predictions/test_predictions_aa685a6f1bc6.json
  - predictions/test_predictions_aa685a6f1bc6.csv
test_results: null
training_results:
  batch_size: 32
  classes:
  - earn
  - acq
  - money-fx
  - grain
  - crude
  - trade
  - interest
  - ship
  - wheat
  - corn
  classification_type: multi_label
  completed: true
  max_completion_tokens: 150
  metrics:
    f1: 0.8802163833075735
    hamming_loss: 0.028438948995363214
    micro_f1: 0.9715610510046367
    micro_precision: 0.9715610510046367
    micro_recall: 0.9715610510046367
    precision: 0.9088098918083463
    recall: 0.8668212261720764
    subset_accuracy: 0.8284389489953632
  model_name: gpt-5-nano
  model_type: llm
  num_labels: 10
  provider: openai
  temperature: 0.1
  test_samples: 647
  train_samples: 5842
